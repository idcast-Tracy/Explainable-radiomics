{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   #  ---------------XGBoost-Survival-SHAP--------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import shap\n",
    "import xgboost\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pylab as pl\n",
    "import warnings\n",
    "from pandas import DataFrame\n",
    "warnings.filterwarnings(action='ignore')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "zh = DataFrame(np.arange(1).reshape(1,1))\n",
    "\n",
    "dataDir = r'E:\\My_project_NPC\\XGB-Cox'\n",
    "train_filename = '/T1_T2_risk_train.csv'\n",
    "test_filename = '/T1_T2_risk_test.csv'\n",
    "val_filename = '/T1_T2_risk_val.csv'\n",
    "train_data = pd.read_csv(dataDir + train_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cc = 3\n",
    "y_train = (np.where(train_data.iloc[:, 1] == 0, -1, train_data.iloc[:, 1])) * train_data.iloc[:, 2]\n",
    "x_train = train_data.iloc[:,cc:]\n",
    "\n",
    "## --------------------internal validation----------------------\n",
    "test_data = pd.read_csv(dataDir + test_filename)\n",
    "x_test = test_data.iloc[:,cc:]\n",
    "y_test = (np.where(test_data.iloc[:, 1] == 0, -1, test_data.iloc[:, 1])) * test_data.iloc[:, 2]\n",
    "\n",
    "## --------------------external validation----------------------\n",
    "val_data = pd.read_csv(dataDir + val_filename)\n",
    "x_val = val_data.iloc[:,cc:]\n",
    "y_val = (np.where(val_data.iloc[:, 1] == 0, -1, val_data.iloc[:, 1])) * val_data.iloc[:, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# --------------- model save ----------------------\n",
    "import time\n",
    "format_date = time.strftime(\"Model_%Y-%m-%d_%H.%M\", time.localtime(time.time()))\n",
    "import os\n",
    "os.mkdir(dataDir + '/' + format_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import xgboost\n",
    "train = xgboost.DMatrix(x_train,y_train)\n",
    "test = xgboost.DMatrix(x_test,y_test)\n",
    "dtrain = xgboost.DMatrix(x_train)\n",
    "dtest = xgboost.DMatrix(x_test)\n",
    "dval = xgboost.DMatrix(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from lifelines.utils import concordance_index\n",
    "best_score = 0\n",
    "score_list = []\n",
    "print('Baseline:', best_score)\n",
    "for seed in [1014]:  ## optimal hyperparameters\n",
    "    for n_estimators in [7]: \n",
    "        for max_depth in [3]:\n",
    "            for colsample_bytree in [0.5]:\n",
    "                for subsample in [0.3]:\n",
    "                    for child in [2]:\n",
    "                        for eta in [0.3]:\n",
    "                            for gamma in [1]:\n",
    "                                for lambda1 in [0.00005]:\n",
    "                                    for alpha in [0.001]:\n",
    "                                        for min_child_weight in [2]:\n",
    "                                            model_forest = xgboost.train(\n",
    "                                                {'objective': 'survival:cox', 'max_depth': max_depth, 'colsample_bytree': colsample_bytree,\n",
    "                                                 'min_child_weight': min_child_weight, 'subsample': subsample, 'booster': 'gbtree', 'eta': eta,\n",
    "                                                 'gamma':gamma, 'lambda':lambda1,'alpha':alpha,'min_child_weight':min_child_weight,\n",
    "                                                 'random_state':seed}, train, n_estimators)\n",
    "                                            train_score = round(concordance_index(train_data['futime'], -model_forest.predict(dtrain), train_data['fustat']), 3)\n",
    "                                            test_score = round(concordance_index( test_data['futime'], -model_forest.predict( dtest),  test_data['fustat']), 3)\n",
    "                                            val_score = round(concordance_index(  val_data['futime'], -model_forest.predict(  dval),   val_data['fustat']), 3)\n",
    "                                            score = min(round(train_score,3), round(test_score,3), round(val_score,3))\n",
    "                                            \n",
    "                                            if score > best_score:\n",
    "                                                best_score = score\n",
    "                                                best_parameters = {'seed': seed, 'estimators': n_estimators, 'depth': max_depth,'gamma':gamma,'alpha':alpha,'min_child_weight':min_child_weight,\n",
    "                                                                   'lambda':lambda1,'colsample': colsample_bytree, 'subsample': subsample, \n",
    "                                                                   'eta':eta}\n",
    "                                                best_model = model_forest\n",
    "                                                print('\\nBest_score', round(best_score, 3), train_score, test_score, val_score)\n",
    "                                                print(best_parameters)\n",
    "print('\\ finish')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------forest model save-------------------------------------\n",
    "import joblib\n",
    "print(dataDir + '\\\\\\\\' + format_date + '\\\\\\\\' + '  model_Xgboost.pkl')\n",
    "joblib.dump(best_model, dataDir + '\\\\\\\\' + format_date + '\\\\\\\\' +'Model_Xgboost.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_score = concordance_index(train_data['futime'], -best_model.predict(dtrain), train_data['fustat'])\n",
    "test_score = concordance_index(test_data['futime'], -best_model.predict(dtest), test_data['fustat'])\n",
    "val_score = concordance_index(val_data['futime'], -best_model.predict(dval), val_data['fustat'])\n",
    "print('\\ntrain_score',round(train_score,3),'\\ntest_score', round(test_score,3),'\\nval_score', round(val_score,3))\n",
    "\n",
    "train_data['riskScore'] = best_model.predict(dtrain)\n",
    "test_data['riskScore'] = best_model.predict(dtest)\n",
    "val_data['riskScore'] = best_model.predict(dval)\n",
    "train_data.to_csv(dataDir + '/' + format_date + '/risk-train.csv')\n",
    "test_data.to_csv(dataDir + '/' + format_date + '/risk-test.csv')\n",
    "val_data.to_csv(dataDir + '/' + format_date + '/risk-val.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ---------------------SHAP ---------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import shap\n",
    "shap.initjs()\n",
    "explainer = shap.TreeExplainer(best_model)\n",
    "shap_values = explainer(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#-------------------summary plot--------------------\n",
    "Max_display = 10\n",
    "\n",
    "myfig = plt.gcf()\n",
    "sum_shap_values = explainer.shap_values(x_train)\n",
    "shap.summary_plot(sum_shap_values, x_train, max_display=Max_display) #, plot_type=\"violin\"\n",
    "myfig.savefig(dataDir + '\\\\' + format_date + '\\\\' + '2. Beeswarm_train.pdf',dpi=300,bbox_inches = 'tight')\n",
    "\n",
    "myfig = plt.gcf()\n",
    "sum_shap_values_test = explainer.shap_values(x_test)\n",
    "shap.summary_plot(sum_shap_values_test, x_test, max_display=Max_display) # , plot_type=\"violin\"\n",
    "myfig.savefig(dataDir + '\\\\' + format_date + '\\\\' + '2. Beeswarm_test.pdf',dpi=300,bbox_inches = 'tight')\n",
    "\n",
    "myfig = plt.gcf()\n",
    "sum_shap_values_val = explainer.shap_values(x_val)\n",
    "shap.summary_plot(sum_shap_values_val, x_val, max_display=Max_display) # , plot_type=\"violin\"\n",
    "myfig.savefig(dataDir + '\\\\' + format_date + '\\\\' + '3. Beeswarm_val.pdf',dpi=300,bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for column in x_train.columns:\n",
    "    shap.plots.scatter(shap_values[:, column], color=shap_values[:,column],show=False)\n",
    "    myfig = plt.gcf()\n",
    "    shap.plots.scatter(shap_values[:, column], color=shap_values[:,column],show=False)\n",
    "    myfig.savefig(dataDir + '\\\\' + format_date + '\\\\' + column +'.tiff',dpi=300)\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#--------------force plot-----------------\n",
    "for i in range(0, 30, 1):\n",
    "    plt.clf()\n",
    "    shap.initjs()\n",
    "    shap.plots.waterfall(shap_values[i], show=False)\n",
    "    myfig = plt.gcf()\n",
    "    print(\"id:\", i + 1)\n",
    "    myfig.savefig(dataDir + '\\\\' + format_date + '\\\\' + str(i+1)+'.tif',dpi=300,bbox_inches = 'tight')\n",
    "    myfig.savefig(dataDir + '\\\\' + format_date + '\\\\' + str(i+1)+'.pdf',dpi=300,bbox_inches = 'tight')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
